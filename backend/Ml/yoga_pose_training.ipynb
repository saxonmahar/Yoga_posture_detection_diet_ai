{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yoga Pose Detection Training and Analysis\n",
    "\n",
    "This notebook helps you train and improve your yoga pose detection model using MediaPipe landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Analyze Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(data_dir=\"training_data\"):\n",
    "    \"\"\"Load training data from collected samples\"\"\"\n",
    "    landmarks_dir = os.path.join(data_dir, \"landmarks\")\n",
    "    \n",
    "    if not os.path.exists(landmarks_dir):\n",
    "        print(f\"‚ùå Training data directory not found: {landmarks_dir}\")\n",
    "        print(\"üí° Run collect_training_data.py first to collect samples\")\n",
    "        return None\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(landmarks_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(landmarks_dir, filename)\n",
    "            \n",
    "            with open(filepath, 'r') as f:\n",
    "                sample = json.load(f)\n",
    "                data.append(sample)\n",
    "    \n",
    "    print(f\"üìä Loaded {len(data)} training samples\")\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "training_data = load_training_data()\n",
    "\n",
    "if training_data:\n",
    "    # Analyze the dataset\n",
    "    poses = [sample['pose_name'] for sample in training_data]\n",
    "    pose_counts = pd.Series(poses).value_counts()\n",
    "    \n",
    "    print(\"\\nüìà Dataset Overview:\")\n",
    "    print(pose_counts)\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    pose_counts.plot(kind='bar')\n",
    "    plt.title('Training Samples per Pose')\n",
    "    plt.xlabel('Pose')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(landmarks):\n",
    "    \"\"\"Extract features from MediaPipe landmarks\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Basic landmark coordinates (normalized)\n",
    "    for lm in landmarks:\n",
    "        features.extend([lm['x'], lm['y'], lm['z'], lm['visibility']])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def calculate_pose_angles(landmarks):\n",
    "    \"\"\"Calculate key angles from landmarks\"\"\"\n",
    "    angles = {}\n",
    "    \n",
    "    def calc_angle(p1, p2, p3):\n",
    "        \"\"\"Calculate angle between three points\"\"\"\n",
    "        a = np.array([p1['x'], p1['y']])\n",
    "        b = np.array([p2['x'], p2['y']])\n",
    "        c = np.array([p3['x'], p3['y']])\n",
    "        \n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians * 180.0 / np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360 - angle\n",
    "        \n",
    "        return angle\n",
    "    \n",
    "    # Key body angles\n",
    "    try:\n",
    "        # Knee angles\n",
    "        angles['left_knee'] = calc_angle(landmarks[23], landmarks[25], landmarks[27])  # Hip-Knee-Ankle\n",
    "        angles['right_knee'] = calc_angle(landmarks[24], landmarks[26], landmarks[28])\n",
    "        \n",
    "        # Elbow angles\n",
    "        angles['left_elbow'] = calc_angle(landmarks[11], landmarks[13], landmarks[15])  # Shoulder-Elbow-Wrist\n",
    "        angles['right_elbow'] = calc_angle(landmarks[12], landmarks[14], landmarks[16])\n",
    "        \n",
    "        # Hip angles\n",
    "        angles['left_hip'] = calc_angle(landmarks[11], landmarks[23], landmarks[25])  # Shoulder-Hip-Knee\n",
    "        angles['right_hip'] = calc_angle(landmarks[12], landmarks[24], landmarks[26])\n",
    "        \n",
    "        # Shoulder angles\n",
    "        angles['left_shoulder'] = calc_angle(landmarks[13], landmarks[11], landmarks[23])  # Elbow-Shoulder-Hip\n",
    "        angles['right_shoulder'] = calc_angle(landmarks[14], landmarks[12], landmarks[24])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating angles: {e}\")\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def create_feature_dataset(training_data):\n",
    "    \"\"\"Create feature dataset for machine learning\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for sample in training_data:\n",
    "        landmarks = sample['landmarks']\n",
    "        pose_name = sample['pose_name']\n",
    "        \n",
    "        # Extract basic features\n",
    "        sample_features = extract_features(landmarks)\n",
    "        \n",
    "        # Add angle features\n",
    "        angles = calculate_pose_angles(landmarks)\n",
    "        sample_features.extend(list(angles.values()))\n",
    "        \n",
    "        features.append(sample_features)\n",
    "        labels.append(pose_name)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "if training_data:\n",
    "    # Create feature dataset\n",
    "    X, y = create_feature_dataset(training_data)\n",
    "    print(f\"\\nüéØ Feature dataset created:\")\n",
    "    print(f\"   Features shape: {X.shape}\")\n",
    "    print(f\"   Labels shape: {y.shape}\")\n",
    "    print(f\"   Unique poses: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Pose Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data and len(training_data) > 10:  # Need minimum samples\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_score = rf_model.score(X_train_scaled, y_train)\n",
    "    test_score = rf_model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print(f\"\\nüéØ Model Performance:\")\n",
    "    print(f\"   Training accuracy: {train_score:.3f}\")\n",
    "    print(f\"   Test accuracy: {test_score:.3f}\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    print(\"\\nüìä Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=rf_model.classes_, \n",
    "                yticklabels=rf_model.classes_)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    \n",
    "    # Save the model\n",
    "    model_dir = \"models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    joblib.dump(rf_model, f\"{model_dir}/pose_classifier.pkl\")\n",
    "    joblib.dump(scaler, f\"{model_dir}/feature_scaler.pkl\")\n",
    "    \n",
    "    print(f\"\\nüíæ Model saved to {model_dir}/\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Not enough training data. Collect at least 10 samples per pose.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Pose Detection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_realtime_detection():\n",
    "    \"\"\"Test the trained model with real-time webcam input\"\"\"\n",
    "    \n",
    "    # Load trained model\n",
    "    try:\n",
    "        model = joblib.load(\"models/pose_classifier.pkl\")\n",
    "        scaler = joblib.load(\"models/feature_scaler.pkl\")\n",
    "        print(\"‚úÖ Loaded trained model\")\n",
    "    except:\n",
    "        print(\"‚ùå No trained model found. Train the model first.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize MediaPipe\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    \n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print(\"üé• Starting real-time pose detection...\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Mirror frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        \n",
    "        # Process with MediaPipe\n",
    "        results = pose.process(frame_rgb)\n",
    "        \n",
    "        # Convert back to BGR\n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # Draw landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_bgr,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            # Extract features for prediction\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            landmark_data = []\n",
    "            \n",
    "            for lm in landmarks:\n",
    "                landmark_data.append({\n",
    "                    'x': lm.x, 'y': lm.y, 'z': lm.z, 'visibility': lm.visibility\n",
    "                })\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_features(landmark_data)\n",
    "            angles = calculate_pose_angles(landmark_data)\n",
    "            features.extend(list(angles.values()))\n",
    "            \n",
    "            # Predict pose\n",
    "            features_scaled = scaler.transform([features])\n",
    "            prediction = model.predict(features_scaled)[0]\n",
    "            confidence = np.max(model.predict_proba(features_scaled))\n",
    "            \n",
    "            # Display prediction\n",
    "            cv2.putText(frame_bgr, f\"Pose: {prediction}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame_bgr, f\"Confidence: {confidence:.2f}\", (10, 70), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Pose Detection Test', frame_bgr)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Uncomment to test real-time detection\n",
    "# test_realtime_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Improved Pose Detection Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pose_characteristics(training_data):\n",
    "    \"\"\"Analyze characteristics of each pose for better rule-based detection\"\"\"\n",
    "    \n",
    "    pose_stats = {}\n",
    "    \n",
    "    for sample in training_data:\n",
    "        pose_name = sample['pose_name']\n",
    "        landmarks = sample['landmarks']\n",
    "        \n",
    "        if pose_name not in pose_stats:\n",
    "            pose_stats[pose_name] = {\n",
    "                'angles': [],\n",
    "                'samples': 0\n",
    "            }\n",
    "        \n",
    "        # Calculate angles for this sample\n",
    "        angles = calculate_pose_angles(landmarks)\n",
    "        pose_stats[pose_name]['angles'].append(angles)\n",
    "        pose_stats[pose_name]['samples'] += 1\n",
    "    \n",
    "    # Calculate statistics for each pose\n",
    "    pose_rules = {}\n",
    "    \n",
    "    for pose_name, stats in pose_stats.items():\n",
    "        if stats['samples'] < 3:  # Need minimum samples\n",
    "            continue\n",
    "            \n",
    "        angles_df = pd.DataFrame(stats['angles'])\n",
    "        \n",
    "        pose_rules[pose_name] = {\n",
    "            'mean_angles': angles_df.mean().to_dict(),\n",
    "            'std_angles': angles_df.std().to_dict(),\n",
    "            'min_angles': angles_df.min().to_dict(),\n",
    "            'max_angles': angles_df.max().to_dict(),\n",
    "            'samples': stats['samples']\n",
    "        }\n",
    "    \n",
    "    return pose_rules\n",
    "\n",
    "def generate_detection_rules(pose_rules):\n",
    "    \"\"\"Generate improved detection rules based on training data\"\"\"\n",
    "    \n",
    "    detection_code = \"\"\"\n",
    "# Auto-generated pose detection rules based on training data\n",
    "# Generated on: {}\n",
    "\n",
    "POSE_DETECTION_RULES = {{\n",
    "\"\"\".format(datetime.now().isoformat())\n",
    "    \n",
    "    for pose_name, rules in pose_rules.items():\n",
    "        detection_code += f'    \"{pose_name}\": {{\\n'\n",
    "        detection_code += f'        \"name\": \"{pose_name.replace(\"_\", \" \").title()}\",\\n'\n",
    "        detection_code += f'        \"samples_used\": {rules[\"samples\"]},\\n'\n",
    "        detection_code += f'        \"ideal_angles\": {{\\n'\n",
    "        \n",
    "        for angle_name, mean_val in rules['mean_angles'].items():\n",
    "            std_val = rules['std_angles'].get(angle_name, 10)\n",
    "            detection_code += f'            \"{angle_name}\": {mean_val:.1f},  # ¬±{std_val:.1f}\\n'\n",
    "        \n",
    "        detection_code += f'        }},\\n'\n",
    "        detection_code += f'        \"tolerance_ranges\": {{\\n'\n",
    "        \n",
    "        for angle_name, std_val in rules['std_angles'].items():\n",
    "            tolerance = max(10, std_val * 2)  # At least 10 degrees tolerance\n",
    "            detection_code += f'            \"{angle_name}\": {tolerance:.1f},\\n'\n",
    "        \n",
    "        detection_code += f'        }}\\n'\n",
    "        detection_code += f'    }},\\n'\n",
    "    \n",
    "    detection_code += \"}\\n\"\n",
    "    \n",
    "    return detection_code\n",
    "\n",
    "if training_data:\n",
    "    # Analyze pose characteristics\n",
    "    pose_rules = analyze_pose_characteristics(training_data)\n",
    "    \n",
    "    print(\"üìä Pose Analysis Results:\")\n",
    "    for pose_name, rules in pose_rules.items():\n",
    "        print(f\"\\n{pose_name} ({rules['samples']} samples):\")\n",
    "        for angle_name, mean_val in rules['mean_angles'].items():\n",
    "            std_val = rules['std_angles'].get(angle_name, 0)\n",
    "            print(f\"  {angle_name}: {mean_val:.1f}¬∞ ¬±{std_val:.1f}¬∞\")\n",
    "    \n",
    "    # Generate improved detection rules\n",
    "    detection_code = generate_detection_rules(pose_rules)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(\"improved_pose_rules.py\", \"w\") as f:\n",
    "        f.write(detection_code)\n",
    "    \n",
    "    print(\"\\nüíæ Improved detection rules saved to 'improved_pose_rules.py'\")\n",
    "    print(\"üîÑ You can now integrate these rules into your pose_detector.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "1. **Collect More Data**: Use `collect_training_data.py` to gather more samples\n",
    "2. **Improve Features**: Add more sophisticated angle calculations and body ratios\n",
    "3. **Try Different Models**: Experiment with SVM, Neural Networks, etc.\n",
    "4. **Real-time Integration**: Integrate the trained model into your main application\n",
    "5. **Continuous Learning**: Set up a system to continuously improve with user feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}